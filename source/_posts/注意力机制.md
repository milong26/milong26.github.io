---
title: 注意力机制
tags: attention
categories: ai
mathjax: true
date: 2024-03-05 16:49:09
---

注意力机制是transformer的核心，有三个关键的计算QKV
<!--more-->
有几个问题：
1. 自注意力(self attention)和注意力(attention)是不是一个？
2. QKV的计算过程
3. attention的输入输出和完整流程
4. 多头注意力里的“多头”是什么概念
# 引入
attention提出之前有CNN和RNN，还需要attention的原因：
（1）计算能力的限制：当要记住很多“信息“，模型就要变得更复杂，然而目前计算能力依然是限制神经网络发展的瓶颈。

（2）优化算法的限制：LSTM只能在一定程度上缓解RNN中的长距离依赖问题，且信息“记忆”能力并不高。
# 基础
attention过程计算的三个阶段：
1. 根据Query和Key计算权重系数
   1. 根据Query和Key计算两者的相似性或者相关性；
   2. 对上一步的原始分值进行归一化处理
2. 根据权重系数对Value进行加权求和

> 本来以为attention很麻烦的，结果看下来它的框架还是很简单的。

# 自注意力
> Q1解决了，自注意力和注意力不一样。之前一直分不清楚这俩

自注意力(self-attention)是transformer里面的，它减少了对外部信息的依赖，更擅长捕捉数据或特征的内部相关性。

## 计算过程
1. 将输入单词转化成嵌入向量；
2. 根据嵌入向量得到q，k，v三个向量；
3. 为每个向量计算一个score：score =q . k ；
4. 为了梯度的稳定，Transformer使用了score归一化，即除以$\sqrt{d_k}$；
5. 对score施以softmax激活函数；
6. softmax点乘Value值v，得到加权的每个输入向量的评分v；
7. 相加之后得到最终的输出结果z ：z=$\sum v$

> Q2和Q3来了

### embedding转换
嵌入只发生在最底层的编码器中
### qkv计算
随机初始化3个矩阵：
$$
W^Q\in R^{d\times d_q}\\
W^K\in R^{d\times d_k}\\
W^V\in R^{d\times d_v}
$$
d是embedding时候一个行向量的维度。
W和它上标在一起是一个整体，命名成w1，w2，w3也行
$$
Q=X\cdot W^Q\\
K=X\cdot W^K\\
V=X\cdot W^V
$$
X是经过embedding的，n行（单词个数）d列（维度）
### score
用的是“点注意力”。另外还有很多算法，transformer用的也是点
从推荐系统开始：
基本原理是：给定一个 query，计算query 与 key 的相关性，然后根据query 与 key 的相关性去找到最合适的 value。
球的score其实就是相关性

### 归一化
为什么要归一化？
随着$d_k$变大，$q\cdot k$的结果也变大。这样会将softmax函数推入梯度非常小的区域，使得收敛困难(可能出现梯度消失的情况)

假设q和k是均值0，方差1的独立随机变量，$q\cdot k=\sum_{i=1}^{d_k}q_ik_i$均值为0，方差$d_k$，为了抵消这种影响，需要缩放

怎么抵消的看一看[这篇包含概率期望方差计算的推导](http://t.csdnimg.cn/WqKbt)

# 变体
## 多头注意力
$$
Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})\\
MultiHead(Q,K,V)=concat(head_1...head_h)W^O\\
where \space head_i=Attention(QW^Q_i,KW_i^K,VW_i^v)
$$
> 一下子看不懂，以后看transformer的时候再琢磨吧