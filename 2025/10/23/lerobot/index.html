<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zhon.fun","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="用lerobot的ur5 dataset。">
<meta property="og:type" content="article">
<meta property="og:title" content="lerobot">
<meta property="og:url" content="http://zhon.fun/2025/10/23/lerobot/index.html">
<meta property="og:site_name" content="没啥标题">
<meta property="og:description" content="用lerobot的ur5 dataset。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-23T06:41:46.000Z">
<meta property="article:modified_time" content="2025-11-20T06:37:10.832Z">
<meta property="article:author" content="milong26">
<meta property="article:tag" content="robot">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://zhon.fun/2025/10/23/lerobot/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://zhon.fun/2025/10/23/lerobot/","path":"2025/10/23/lerobot/","title":"lerobot"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>lerobot | 没啥标题</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">没啥标题</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">活下去</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%89%E8%A3%85"><span class="nav-number">1.</span> <span class="nav-text">安装</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD"><span class="nav-number">2.</span> <span class="nav-text">数据集下载</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%86%85%E5%AE%B9"><span class="nav-number">3.</span> <span class="nav-text">数据集内容</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">4.</span> <span class="nav-text">数据集可视化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#berkeley-ur5"><span class="nav-number">5.</span> <span class="nav-text">Berkeley UR5</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#npy-data"><span class="nav-number">5.1.</span> <span class="nav-text">npy data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#read"><span class="nav-number">5.1.1.</span> <span class="nav-text">read</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#save"><span class="nav-number">5.1.2.</span> <span class="nav-text">save</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#robot_state-np.ndarrayl-15"><span class="nav-number">5.1.2.1.</span> <span class="nav-text">robot_state: np.ndarray((L,
15))</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#image-np.ndarrayl-480-640-3"><span class="nav-number">5.1.2.2.</span> <span class="nav-text">image: np.ndarray((L, 480, 640,
3))</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#qpos%E5%AF%BC%E5%85%A5genesis"><span class="nav-number">5.2.</span> <span class="nav-text">qpos导入genesis</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E7%90%86"><span class="nav-number">6.</span> <span class="nav-text">服务器推理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%84"><span class="nav-number">7.</span> <span class="nav-text">运行结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lerobot%E7%94%A8pi0.5%E8%AE%AD%E7%BB%83pusht"><span class="nav-number">8.</span> <span class="nav-text">lerobot用pi0.5训练pusht</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#dataset"><span class="nav-number">8.1.</span> <span class="nav-text">dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E8%AE%BE%E7%BD%AE-hf_endpoint%E4%B8%80%E6%AC%A1%E6%80%A7%E7%A4%BA%E4%BE%8B"><span class="nav-number">8.2.</span> <span class="nav-text">一、设置
HF_ENDPOINT（一次性示例）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E6%98%AF%E5%90%A6%E8%AE%BE%E7%BD%AE%E6%88%90%E5%8A%9F"><span class="nav-number">8.2.1.</span> <span class="nav-text">验证是否设置成功</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#action%E8%BD%AC%E6%8D%A2"><span class="nav-number">9.</span> <span class="nav-text">action转换</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#async"><span class="nav-number">10.</span> <span class="nav-text">async</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#async-action%E7%9B%B8%E5%85%B3%E7%BB%93%E6%9E%84"><span class="nav-number">10.0.0.1.</span> <span class="nav-text">async-action相关结构</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E6%8E%A8%E7%90%86action%E6%95%B0%E6%8D%AE%E6%B5%81%E5%AE%8C%E6%95%B4%E6%97%B6%E5%BA%8F%E5%9B%BE"><span class="nav-number">10.0.0.1.1.</span> <span class="nav-text">异步推理Action数据流完整时序图</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#async-inferece-action-on-cpu"><span class="nav-number">10.0.1.</span> <span class="nav-text">async inferece action on cpu</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lerobot%E8%87%AA%E5%B7%B1%E6%8F%90%E4%BE%9B%E7%9A%84pipeline"><span class="nav-number">11.</span> <span class="nav-text">lerobot自己提供的pipeline</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#record"><span class="nav-number">12.</span> <span class="nav-text">record</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#code-pipeline"><span class="nav-number">12.1.</span> <span class="nav-text">code pipeline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#question-about-code"><span class="nav-number">12.2.</span> <span class="nav-text">question about code</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98joint%E5%BD%A2%E5%BC%8F%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="nav-number">12.3.</span> <span class="nav-text">保存joint形式的数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#record%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96%E5%A4%84%E7%90%86%E4%B8%8E%E4%BF%9D%E5%AD%98"><span class="nav-number">12.3.1.</span> <span class="nav-text">record数据获取、处理与保存</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#metaworld"><span class="nav-number">13.</span> <span class="nav-text">metaworld</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lerobot-ee"><span class="nav-number">14.</span> <span class="nav-text">lerobot-ee</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#record-1"><span class="nav-number">14.1.</span> <span class="nav-text">record</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#evaluate"><span class="nav-number">14.2.</span> <span class="nav-text">evaluate</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#predict_action"><span class="nav-number">14.2.1.</span> <span class="nav-text">predict_action</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#local"><span class="nav-number">14.2.2.</span> <span class="nav-text">local</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#async-1"><span class="nav-number">14.2.3.</span> <span class="nav-text">async</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9async"><span class="nav-number">14.2.3.1.</span> <span class="nav-text">修改async</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#async%E6%89%A7%E8%A1%8C"><span class="nav-number">14.2.3.2.</span> <span class="nav-text">async执行</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C"><span class="nav-number">14.2.3.3.</span> <span class="nav-text">执行</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#debug%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%87%AA%E5%AD%98"><span class="nav-number">15.</span> <span class="nav-text">debug配置文件自存</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="nav-number">15.1.</span> <span class="nav-text">服务器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#async_inference"><span class="nav-number">16.</span> <span class="nav-text">async_inference</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#inference-on-policy_srever"><span class="nav-number">16.1.</span> <span class="nav-text">inference on policy_srever</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">milong26</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">84</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">74</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zhon.fun/2025/10/23/lerobot/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="milong26">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="没啥标题">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="lerobot | 没啥标题">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          lerobot
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-10-23 14:41:46" itemprop="dateCreated datePublished" datetime="2025-10-23T14:41:46+08:00">2025-10-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-11-20 14:37:10" itemprop="dateModified" datetime="2025-11-20T14:37:10+08:00">2025-11-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/it/" itemprop="url" rel="index"><span itemprop="name">it</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>用lerobot的ur5 dataset。</p>
<span id="more"></span>
<h1 id="安装">安装</h1>
<ol type="1">
<li>仿照<a
target="_blank" rel="noopener" href="https://github.com/huggingface/lerobot?tab=readme-ov-file#installation">install</a></li>
<li>linux没啥问题，有一个报错，用python3-dev代替python-dev
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Package python-dev is not available, but is referred to by another package.</span><br><span class="line">This may mean that the package is missing, has been obsoleted or is only available from another source</span><br><span class="line">However the following packages replace it:</span><br><span class="line">  python2-dev:i386 python2:i386 python2-dev python2 python-dev-is-python3</span><br></pre></td></tr></table></figure></li>
<li>pip
install超时，换镜像<code>pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</code></li>
<li>下载会很慢，又超时了，加上--default-timeout=100</li>
</ol>
<h1 id="数据集下载">数据集下载</h1>
<ol type="1">
<li>sudo apt-get install git-lfs</li>
<li>git clone
https://hf-mirror.com/datasets/lerobot/berkeley_autolab_ur5</li>
</ol>
<h1 id="数据集内容">数据集内容</h1>
<ol type="1">
<li><a
target="_blank" rel="noopener" href="https://sites.google.com/view/berkeley-ur5/home">官网</a></li>
<li>task
<ol type="1">
<li>tiger pick and
place：任务字符串是“把老虎从红碗里拿出来，放在灰碗里。“填充动物（老虎）总是从红碗开始。两个碗的位置在桌子上是随机的，而夹持器被初始化为固定姿势。从技术上讲，拾取和放置任务只需要夹持器的平移动作。</li>
<li>cloth
sweeping：任务字符串为“将绿色布扫到桌子左侧。“布料随机初始化在桌子右侧的一个地方，抓手需要将其水平推到左侧。通过从固定位置添加噪声来随机初始化夹持器的起始姿态。从技术上讲，清扫任务只需要抓手的平移动作。</li>
<li>杯子堆叠：任务字符串是“拿起蓝色杯子并将其放入棕色杯子。“两个杯子的位置在桌子上是随机的，抓手的起始姿势也是随机的。从技术上讲，堆叠任务只需要夹持器的平移动作。</li>
<li>瓶子拾取和放置：任务字符串是“将牧场瓶子放入锅中。“锅的位置是固定的，而牧场瓶的位置是随机的。
夹持器的起始姿势是固定的。此任务涉及平移和旋转操作。</li>
</ol></li>
</ol>
<h1 id="数据集可视化">数据集可视化</h1>
<p>python lerobot/scripts/visualize_dataset.py<br />
--repo-id lerobot/berkeley_autolab_ur5<br />
--root ~/<br />
--local-files-only 1<br />
--episode-index 0</p>
<pre><code>怎么又不支持本地的了？？？</code></pre>
<h1 id="berkeley-ur5">Berkeley UR5</h1>
<ol type="1">
<li><a
target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1Tsx4zIPiEFR4kKOsR-cwbPNoPlejBaJn">google
drive下载链接</a></li>
<li>根据<a
target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_40959890/article/details/127393253">pkl,npy比较</a>
选择npy</li>
<li>下bottle.npy（流量肉疼）</li>
</ol>
<h2 id="npy-data">npy data</h2>
<p>这一部分用jupyter 很爽:D</p>
<h3 id="read">read</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 直接加载整个文件（需确保内存足够）</span><br><span class="line">data = np.load(&quot;bottle.npy&quot;,allow_pickle=True)</span><br><span class="line">print(data.shape)  # 查看数组维度</span><br><span class="line">print(data.dtype)  # 查看数据类型</span><br><span class="line">metadata = data.item()</span><br><span class="line">print(metadata.keys())</span><br></pre></td></tr></table></figure>
<p>(1,) object dict_keys(['robot_state', 'action', 'image', 'task',
'other'])</p>
<h3 id="save">save</h3>
<h4 id="robot_state-np.ndarrayl-15">robot_state: np.ndarray((L,
15))</h4>
<ol type="1">
<li>数据说明
<ol type="1">
<li>This stores the robot state at each timestep.</li>
<li>[joint0, joint1, joint2, joint3, joint4, joint5, x,y,z, qx,qy,qz,qw,
gripper_is_closed, action_blocked]</li>
<li>x,y,z, qx,qy,qz,qw is the end-effector pose expressed in the robot
base frame</li>
<li>gripper_is_closed is binary: 0 = fully open; 1 = fully closed</li>
<li>action_blocked is binary: 1 if the gripper opening/closing action is
being executed and no other actions can be performed; 0 otherwise.</li>
<li>有用的是0-5，以及倒数2，倒数1不知道有没有用</li>
</ol></li>
<li>代码 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 假设 metadata[&#x27;robot_state&#x27;] 是形状为 (L,15) 的 numpy 数组</span></span><br><span class="line">robot_state_data = metadata[<span class="string">&#x27;robot_state&#x27;</span>]</span><br><span class="line"><span class="comment"># 提取目标字段：joint0-joint5 (索引0-5) + gripper_is_closed (索引13)</span></span><br><span class="line">target_indices = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">13</span>]  <span class="comment"># 需要提取的列索引</span></span><br><span class="line">output_lines = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> state <span class="keyword">in</span> robot_state_data:</span><br><span class="line">    <span class="comment"># 提取指定列并转换为列表[6,8](@ref)</span></span><br><span class="line">    extracted = [state[i] <span class="keyword">for</span> i <span class="keyword">in</span> target_indices]</span><br><span class="line">    <span class="comment"># 格式化为字符串（保留4位小数，二进制用整数）</span></span><br><span class="line">    line = <span class="string">&quot; &quot;</span>.join([<span class="string">f&quot;<span class="subst">&#123;x:<span class="number">.4</span>f&#125;</span>&quot;</span> <span class="keyword">if</span> i &lt; <span class="number">6</span> <span class="keyword">else</span> <span class="built_in">str</span>(<span class="built_in">int</span>(x)) <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(extracted)])</span><br><span class="line">    output_lines.append(line)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入TXT文件（使用UTF-8编码保证兼容性）[9,11](@ref)</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;robot_joints_gripper.txt&quot;</span>, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&quot;\n&quot;</span>.join(output_lines))</span><br></pre></td></tr></table></figure></li>
</ol>
<p>使用的时候 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_robot_data</span>(<span class="params">file_path</span>):</span><br><span class="line">    data_list = []</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            <span class="comment"># 去除换行符并分割数据[6,9](@ref)</span></span><br><span class="line">            raw_values = line.strip().split()</span><br><span class="line">            <span class="comment"># 转换数据类型：前6个为float，最后1个为int[8](@ref)</span></span><br><span class="line">            converted = [<span class="built_in">float</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> raw_values[:<span class="number">6</span>]] + [<span class="built_in">int</span>(raw_values[-<span class="number">1</span>])]</span><br><span class="line">            data_list.append(converted)</span><br><span class="line">    <span class="keyword">return</span> data_list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line">loaded_data = read_robot_data(<span class="string">&quot;robot_joints_gripper.txt&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;加载数据量：<span class="subst">&#123;<span class="built_in">len</span>(loaded_data)&#125;</span> 条&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;首条数据示例：&quot;</span>, loaded_data[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<h4 id="image-np.ndarrayl-480-640-3">image: np.ndarray((L, 480, 640,
3))</h4>
<ol type="1">
<li>除了这个image，other里面还有点，只保存这个</li>
<li>代码 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line"># 假设 images 是形状为 (L, 480, 640, 3) 的 uint8 数组</span><br><span class="line">for i in range(image_data.shape[0]):</span><br><span class="line">    img = Image.fromarray(image_data[i])  # 提取单张图像</span><br><span class="line">    # img.save(f&quot;images/image_&#123;i&#125;.jpg&quot;)        # 保存为JPG</span><br><span class="line">    # 或保存为PNG（无损压缩）</span><br><span class="line">    img.save(f&quot;images/image_&#123;i&#125;.png&quot;, &quot;PNG&quot;, compress_level=0)</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="qpos导入genesis">qpos导入genesis</h2>
<ol type="1">
<li>提取qpos</li>
<li>提取gripper，就这些</li>
</ol>
<h1 id="服务器推理">服务器推理</h1>
<h1 id="运行结构">运行结构</h1>
<h1 id="lerobot用pi0.5训练pusht">lerobot用pi0.5训练pusht</h1>
<h2 id="dataset">dataset</h2>
<p>数据集格式估计不对</p>
<p>Migrate v2.1 → v3.0
https://huggingface.co/docs/lerobot/lerobot-dataset-v3</p>
<p>python -m lerobot.datasets.v30.convert_dataset_v21_to_v30
--repo-id=<HF_USER/DATASET_ID></p>
<p>但是代码运行之前需要加一个PYTHONPATH=src</p>
<p>现在用root/repo_id表示数据集的位置了，跟以前不一样</p>
<p>好像是v3的特性把所有的episode存到一起 ## model</p>
<p>pip install -e ".[pi]"</p>
<p>准备号pi0_base和pi05_base：huggingface的下载不了就下hf-mirror.com的</p>
<p>这个训练命令行太难看了</p>
<p>hf download
repo_id之后不用改变位置，直接pretrained_path_or_name就能用。
除了base模型还需要下载分词器，但是分词器google/paligemma-3b-pt-224需要获取token才能下载，教程：https://hf-mirror.com/login
获得token之后 hf download google/paligemma-3b-pt-224 --token
刚刚复制得到的token</p>
<p>HF_HUB_OFFLINE=1 CUDA_VISIBLE_DEVICES=0 python
src/lerobot/scripts/lerobot_train.py
--config_path=fscript/finetune/simple_test.yaml</p>
<p>这样断网+只用一个gpu，现在可以加载1. 分词器，2. 基础模型</p>
<p>To run the models in this repository, you will need an NVIDIA GPU
with at least the following specifications. These estimations assume a
single GPU, but you can also use multiple GPUs with model parallelism to
reduce per-GPU memory requirements by configuring
<code>fsdp_devices</code> in the training config. Please also note that
the current training script does not yet support multi-node
training.</p>
<p>根据pi05的要求，恐怕不能微调……</p>
<div class="line-block">Mode               | Memory Required | Example
GPU        |</div>
<div class="line-block">------------------ | --------------- |
------------------ |</div>
<div class="line-block">Inference          | &gt; 8 GB          | RTX
4090           |</div>
<div class="line-block">Fine-Tuning (LoRA) | &gt; 22.5 GB       | RTX
4090           |</div>
<div class="line-block">Fine-Tuning (Full) | &gt; 70 GB         | A100
(80GB) / H100 |</div>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">python src/lerobot/scripts/lerobot_train.py \</span><br><span class="line">    --dataset.repo_id=your_dataset \</span><br><span class="line">    --policy.type=pi0 \</span><br><span class="line">    --output_dir=./outputs/pi0_training \</span><br><span class="line">    --job_name=pi0_training \</span><br><span class="line">    --policy.pretrained_path=lerobot/pi0_base \</span><br><span class="line">    --policy.repo_id=your_repo_id \</span><br><span class="line">    --policy.compile_model=true \</span><br><span class="line">    --policy.gradient_checkpointing=true \</span><br><span class="line">    --policy.dtype=bfloat16 \</span><br><span class="line">    --steps=3000 \</span><br><span class="line">    --policy.device=cuda \</span><br><span class="line">    --batch_size=32</span><br></pre></td></tr></table></figure>
<p>改成 HF_HUB_OFFLINE=1 CUDA_VISIBLE_DEVICES=0 python
src/lerobot/scripts/lerobot_train.py
--config_path=fscript/finetune/simple_test.yaml</p>
<p>其中simple_test.yaml <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参考pi0 https://huggingface.co/docs/lerobot/pi0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用pusht数据finetune pi0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 已经可以用multi gpu training了：https://huggingface.co/docs/lerobot/multi_gpu_training</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CUDA_VISIBLE_DEVICES=0 PYTHONPATH=src lerobot.scripts.lerobot_train --config_path=fscript/finetune/simple_test.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">dataset:</span></span><br><span class="line">  <span class="attr">repo_id:</span> <span class="string">pusht</span></span><br><span class="line">  <span class="attr">root:</span> <span class="string">local/dataset/pusht</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">policy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">pi0</span></span><br><span class="line">  <span class="attr">pretrained_path:</span> <span class="string">lerobot/pi0_base</span></span><br><span class="line">  <span class="attr">repo_id:</span> <span class="string">lerobot/pi0_base</span></span><br><span class="line">  <span class="attr">compile_model:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">gradient_checkpointing:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">dtype:</span> <span class="string">bfloat16</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">device:</span> <span class="string">cuda</span></span><br><span class="line"></span><br><span class="line"><span class="attr">output_dir:</span> <span class="string">outputs/pi0_training</span></span><br><span class="line"><span class="attr">job_name:</span> <span class="string">pi0_training</span></span><br><span class="line"><span class="attr">steps:</span> <span class="number">3000</span></span><br><span class="line"><span class="attr">batch_size:</span> <span class="number">32</span></span><br></pre></td></tr></table></figure></p>
<p>原来支持multi-gpu training了<a
target="_blank" rel="noopener" href="https://huggingface.co/docs/lerobot/multi_gpu_training">multi-gpu
training</a></p>
<p>pip install accelerate</p>
<p>想用指定的卡id训练 1. 直接命令行 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HF_HUB_OFFLINE=1 CUDA_VISIBLE_DEVICES=0,1,2 accelerate launch \</span><br><span class="line">  --multi_gpu \</span><br><span class="line">  --num_processes=3 \</span><br><span class="line">  src/lerobot/scripts/lerobot_train.py \</span><br><span class="line">  --config_path=fscript/finetune/simple_test.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<ol start="2" type="1">
<li></li>
</ol>
<p>先放在这里：hf-mirror的设置</p>
<h2 id="一设置-hf_endpoint一次性示例">一、设置
HF_ENDPOINT（一次性示例）</h2>
<blockquote>
<p>若你已在当前终端执行过本行，可跳过</p>
</blockquote>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HF_ENDPOINT=https://hf-mirror.com</span><br></pre></td></tr></table></figure>
<h3 id="验证是否设置成功">验证是否设置成功</h3>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $HF_ENDPOINT</span><br></pre></td></tr></table></figure>
<p>如果输出：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://hf-mirror.com</span><br></pre></td></tr></table></figure>
<p>说明设置已生效。</p>
<ul>
<li><p><strong>作用</strong>：让 Hugging Face
相关工具通过镜像站点访问与下载。</p></li>
<li><p><strong>范围</strong>：仅对当前 shell 会话有效（关闭终端失效）。
## 二、检查是否存在代理设置</p></li>
</ul>
<p>下载失败常见原因是 shell 仍保留了代理环境变量。检查方法：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env | grep -i proxy || echo &quot;no proxy env&quot;</span><br></pre></td></tr></table></figure>
<p>若看到如下变量仍存在（示例）：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http_proxy=http://127.0.0.1:7890/</span><br><span class="line">https_proxy=http://127.0.0.1:7890/</span><br><span class="line">HTTP_PROXY=http://127.0.0.1:7890/</span><br><span class="line">HTTPS_PROXY=http://127.0.0.1:7890/</span><br></pre></td></tr></table></figure>
<p>说明请求会强制走本地代理（即使你关闭了代理软件），容易触发 <code>Connection refused</code>。</p>
<blockquote>
<p><code>no_proxy/NO_PROXY</code> 仅表示“这些地址不走代理”，不会影响你直连外网。</p>
</blockquote>
<p>最好选择cli下载方式，http可能需要账户 Make sure hf CLI is installed:
pip install -U "huggingface_hub[cli]"</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hf download lerobot/pi05_base</span><br></pre></td></tr></table></figure>
<p>上面设置只在当前客户端有用
下载的模型放在哪里？.cache/huggingface/hub/models--lerobot--pi0_base/snapshots
应该是这个位置，然后挪到自己要的目录里面</p>
<p>hf download下载的文件在哪里？什么格式？ hf download
lerobot/pi0_base这个命令下载的文件，~/.cache/huggingface/hub/models--lerobot--pi0_base/这个目录里面，有3个文件夹，snapshots,refs和blobs
看起来只有snapshots里面的比较像文件，有文件名而不是奇怪的数字和字母组合，但是，它并不是真正的文件，只是符号链接
~/.cache/huggingface/hub/models--lerobot--pi0_base/snapshots/e3a5218ef7a5903445baf2cb656912fc35dc8712$
ll 总计 12 drwxrwxr-x 2 zhonglinyue zhonglinyue 4096 10月 24 10:39 ./
drwxrwxr-x 3 zhonglinyue zhonglinyue 4096 10月 24 10:31 ../ lrwxrwxrwx 1
zhonglinyue zhonglinyue 52 10月 24 10:31 config.json -&gt;
../../blobs/58354c004ec619bc0b0d16faccf9a3c8f89e922b lrwxrwxrwx 1
zhonglinyue zhonglinyue 52 10月 24 10:31 .gitattributes -&gt;
../../blobs/a6344aac8c09253b3b630fb776ae94478aa0275b lrwxrwxrwx 1
zhonglinyue zhonglinyue 76 10月 24 10:39 model.safetensors -&gt;
../../blobs/8229fd9a7c3c2aafc1e223567b61b5fe3e25eef873bb4233928dbee4bd836303
lrwxrwxrwx 1 zhonglinyue zhonglinyue 52 10月 24 10:31
policy_postprocessor.json -&gt;
../../blobs/4490f0951e4c146a36b9346d36e49c9b676cee23 lrwxrwxrwx 1
zhonglinyue zhonglinyue 52 10月 24 10:31 policy_preprocessor.json -&gt;
../../blobs/ac2b548a787170b0b6bb355ceb54d6c01370032e lrwxrwxrwx 1
zhonglinyue zhonglinyue 52 10月 24 10:31 README.md -&gt;
../../blobs/55fe0bef62c428ef7319989638938e600874e206</p>
<p><code>snapshots/...</code> 目录下的文件都是 <strong>符号链接（symlink）</strong>，指向 <code>blobs/...</code> 目录下的实际文件</p>
<p>这是 Hugging Face Hub 的 <strong>去重存储（content-addressable
storage）</strong> 机制</p>
<p>下载到本地以后直接repo_id，pretrained_path_or_name改成id就能直接访问到了</p>
<h1 id="action转换">action转换</h1>
<p>lerobot里面提供了一个：examples/so100_to_so100_EE，看一下这部分代码做了什么？</p>
<p>四个代码，record，replay，evaluate和teleoperate，分别做</p>
<p><a
target="_blank" rel="noopener" href="https://github.com/box2ai-robotics/lerobot-kinematics/tree/main">lerobot-kinematics</a></p>
<h1 id="async">async</h1>
<h4 id="async-action相关结构">async-action相关结构</h4>
<h5
id="异步推理action数据流完整时序图">异步推理Action数据流完整时序图</h5>
<p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line"> participant Robot as 机器人硬件</span><br><span class="line"> participant Client as RobotClient</span><br><span class="line"> participant Server as PolicyServer</span><br><span class="line"> participant Policy as 策略模型</span><br><span class="line"> participant Queue as 动作队列</span><br><span class="line"></span><br><span class="line"> Note over Client, Server: 1. 初始化连接阶段</span><br><span class="line"> Client-&gt;&gt;Server: Ready()</span><br><span class="line"> Server--&gt;&gt;Client: 连接确认</span><br><span class="line"> Client-&gt;&gt;Server: SendPolicyInstructions(policy_specs)</span><br><span class="line"> Note over Server: 加载策略模型到GPU</span><br><span class="line"> Server-&gt;&gt;Policy: policy_class.from_pretrained()</span><br><span class="line"> Server-&gt;&gt;Policy: policy.to(device)</span><br><span class="line"></span><br><span class="line"> Note over Robot, Queue: 2. 观测-推理-动作循环</span><br><span class="line"> loop 实时控制循环</span><br><span class="line">     Robot-&gt;&gt;Client: capture_observation()</span><br><span class="line">     Note over Client: control_loop_observation()</span><br><span class="line">     Client-&gt;&gt;Client: TimedObservation(timestamp, obs)</span><br><span class="line">     Client-&gt;&gt;Server: SendObservations(timed_obs)</span><br><span class="line">     </span><br><span class="line">     Note over Server: 观测数据处理</span><br><span class="line">     Server-&gt;&gt;Server: _enqueue_observation(timed_obs)</span><br><span class="line">     Server-&gt;&gt;Server: observation_queue.put(timed_obs)</span><br><span class="line"></span><br><span class="line">     par 异步推理</span><br><span class="line">         Client-&gt;&gt;Server: GetActions() [阻塞调用]</span><br><span class="line">         Server-&gt;&gt;Server: observation_queue.get()</span><br><span class="line">         Note over Server: _predict_action_chunk()</span><br><span class="line">         </span><br><span class="line">         Server-&gt;&gt;Server: raw_observation_to_observation()</span><br><span class="line">         Note over Server: 图像预处理 + 状态提取</span><br><span class="line">         </span><br><span class="line">         Server-&gt;&gt;Server: preprocessor(observation)</span><br><span class="line">         Note over Server: tokenization, normalization, batching</span><br><span class="line">         </span><br><span class="line">         Server-&gt;&gt;Policy: _get_action_chunk(observation)</span><br><span class="line">         Policy-&gt;&gt;Policy: predict_action_chunk()</span><br><span class="line">         Policy--&gt;&gt;Server: action_tensor [B, chunk_size, action_dim]</span><br><span class="line">         </span><br><span class="line">         Server-&gt;&gt;Server: postprocessor(action_tensor)</span><br><span class="line">         Note over Server: unnormalization, device movement</span><br><span class="line">         </span><br><span class="line">         Server-&gt;&gt;Server: _time_action_chunk()</span><br><span class="line">         Note over Server: 转换为 TimedAction 列表</span><br><span class="line">         </span><br><span class="line">         Server--&gt;&gt;Client: action_chunk [pickle序列化]</span><br><span class="line">     end</span><br><span class="line"></span><br><span class="line">     Note over Client: 动作处理与执行</span><br><span class="line">     Client-&gt;&gt;Client: receive_actions()</span><br><span class="line">     Client-&gt;&gt;Client: _aggregate_action_queues(incoming_actions)</span><br><span class="line">     </span><br><span class="line">     loop 动作队列聚合</span><br><span class="line">         Client-&gt;&gt;Client: 检查相同时间戳动作</span><br><span class="line">         alt 存在相同时间戳</span><br><span class="line">             Client-&gt;&gt;Client: aggregate_fn(existing, incoming)</span><br><span class="line">         else 新动作</span><br><span class="line">             Client-&gt;&gt;Queue: action_queue.append(timed_action)</span><br><span class="line">         end</span><br><span class="line">     end</span><br><span class="line">     </span><br><span class="line">     Client-&gt;&gt;Client: action_queue.sort(key=timestamp)</span><br><span class="line">     </span><br><span class="line">     Note over Client: control_loop_action()</span><br><span class="line">     Client-&gt;&gt;Queue: 查找当前时间戳动作</span><br><span class="line">     Queue--&gt;&gt;Client: timed_action</span><br><span class="line">     Client-&gt;&gt;Client: _action_tensor_to_action_dict()</span><br><span class="line">     Client-&gt;&gt;Robot: 执行动作指令</span><br><span class="line">     </span><br><span class="line">     Note over Robot: 物理动作执行</span><br><span class="line"> end</span><br></pre></td></tr></table></figure> ##### action数据流变换 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">flowchart TD</span><br><span class="line">A[机器人采集观测] --&gt; B[control_loop_observation]</span><br><span class="line">B --&gt; C[TimedObservation创建]</span><br><span class="line">C --&gt; D[SendObservations序列化发送]</span><br><span class="line"></span><br><span class="line">D --&gt; E[服务器接收观测]</span><br><span class="line">E --&gt; F[_enqueue_observation]</span><br><span class="line">F --&gt; G[observation_queue]</span><br><span class="line"></span><br><span class="line">H[客户端GetActions请求] --&gt; I[observation_queue.get]</span><br><span class="line">I --&gt; J[_predict_action_chunk]</span><br><span class="line"></span><br><span class="line">J --&gt; K[raw_observation_to_observation]</span><br><span class="line">K --&gt; K1[图像resize + 预处理]</span><br><span class="line">K --&gt; K2[状态数据提取]</span><br><span class="line"></span><br><span class="line">K1 --&gt; L[preprocessor处理]</span><br><span class="line">K2 --&gt; L</span><br><span class="line">L --&gt; L1[tokenization]</span><br><span class="line">L --&gt; L2[normalization] </span><br><span class="line">L --&gt; L3[batching]</span><br><span class="line">L --&gt; L4[device placement]</span><br><span class="line"></span><br><span class="line">L4 --&gt; M[策略模型推理]</span><br><span class="line">M --&gt; M1[policy.predict_action_chunk]</span><br><span class="line">M1 --&gt; N[action_tensor: B,chunk_size,action_dim]</span><br><span class="line"></span><br><span class="line">N --&gt; O[postprocessor处理]</span><br><span class="line">O --&gt; O1[unnormalization]</span><br><span class="line">O --&gt; O2[device movement]</span><br><span class="line">O2 --&gt; P[processed_action_tensor]</span><br><span class="line"></span><br><span class="line">P --&gt; Q[_time_action_chunk]</span><br><span class="line">Q --&gt; R[TimedAction列表创建]</span><br><span class="line">R --&gt; S[pickle序列化返回]</span><br><span class="line"></span><br><span class="line">S --&gt; T[客户端receive_actions]</span><br><span class="line">T --&gt; U[反序列化action_chunk]</span><br><span class="line">U --&gt; V[_aggregate_action_queues]</span><br><span class="line"></span><br><span class="line">V --&gt; W&#123;检查时间戳&#125;</span><br><span class="line">W --&gt;|相同时间戳| X[aggregate_fn聚合]</span><br><span class="line">W --&gt;|新时间戳| Y[直接添加到队列]</span><br><span class="line"></span><br><span class="line">X --&gt; Z[action_queue更新]</span><br><span class="line">Y --&gt; Z</span><br><span class="line">Z --&gt; AA[按时间戳排序]</span><br><span class="line"></span><br><span class="line">AA --&gt; BB[control_loop_action]</span><br><span class="line">BB --&gt; CC[查找当前时间戳动作]</span><br><span class="line">CC --&gt; DD[_action_tensor_to_action_dict]</span><br><span class="line">DD --&gt; EE[机器人执行动作]</span><br><span class="line"></span><br><span class="line">style J fill:#e1f5fe</span><br><span class="line">style M1 fill:#fff3e0  </span><br><span class="line">style V fill:#f3e5f5</span><br><span class="line">style BB fill:#e8f5e8</span><br></pre></td></tr></table></figure> #####
异步推理架构 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">subgraph &quot;客户端 (RobotClient)&quot;</span><br><span class="line">	A[机器人硬件] --&gt; B[观测采集]</span><br><span class="line">	B --&gt; C[control_loop_observation]</span><br><span class="line">	C --&gt; D[SendObservations]</span><br><span class="line">	</span><br><span class="line">	H[receive_actions] --&gt; I[动作队列聚合]</span><br><span class="line">	I --&gt; J[control_loop_action]</span><br><span class="line">	J --&gt; K[动作执行]</span><br><span class="line">	K --&gt; A</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">subgraph &quot;gRPC通信层&quot;</span><br><span class="line">	D --&gt; E[观测数据流]</span><br><span class="line">	F[动作数据流] --&gt; H</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">subgraph &quot;服务器端 (PolicyServer)&quot;</span><br><span class="line">	E --&gt; G[observation_queue]</span><br><span class="line">	G --&gt; L[_predict_action_chunk]</span><br><span class="line">	</span><br><span class="line">	subgraph &quot;推理流水线&quot;</span><br><span class="line">		L --&gt; M[数据预处理]</span><br><span class="line">		M --&gt; N[策略推理]</span><br><span class="line">		N --&gt; O[后处理]</span><br><span class="line">		O --&gt; P[TimedAction生成]</span><br><span class="line">	end</span><br><span class="line">	</span><br><span class="line">	P --&gt; F</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">subgraph &quot;关键函数调用&quot;</span><br><span class="line">	Q[raw_observation_to_observation]</span><br><span class="line">	R[policy.predict_action_chunk]</span><br><span class="line">	S[_aggregate_action_queues]</span><br><span class="line">	T[_action_tensor_to_action_dict]</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">M -.-&gt; Q</span><br><span class="line">N -.-&gt; R</span><br><span class="line">I -.-&gt; S</span><br><span class="line">J -.-&gt; T</span><br></pre></td></tr></table></figure></p>
<h3 id="async-inferece-action-on-cpu">async inferece action on cpu</h3>
<p>现在有个bug是服务器推理本地cpu执行，报错说“RuntimeError: Attempting
to deserialize object on a CUDA device but torch.cuda.is_available() is
False. If you are running on a CPU-only machine, please use torch.load
with map_location=torch.device('cpu') to map your storages to the CPU.”
但按照它的该法也会报错</p>
<p>github.com/huggingface/lerobot/issues/2244
提供了一个方案：改policy_server.py，传之前做好cpu转换 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;5. Convert to TimedAction list&quot;&quot;&quot;</span></span><br><span class="line">action_chunk = self._time_action_chunk(</span><br><span class="line">    observation_t.get_timestamp(), <span class="built_in">list</span>(action_tensor.cpu()), observation_t.get_timestep()</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<h1 id="lerobot自己提供的pipeline">lerobot自己提供的pipeline</h1>
<ol type="1">
<li>record的数据逻辑：
<ol type="1">
<li>follower_joints_to_ee：follower当前的状态state（ee格式）</li>
<li>leader_joints_to_ee：leader的目标动作（ee格式）</li>
<li>ee_to_follower_joints：没有像lerobot以前那样joint-&gt;joint的teleoperate方法，而是用leader的ee
action计算follower的joint
action。（那岂不是就能验证它能否teleoperate别的？）</li>
</ol></li>
<li>dataset格式：
<ol type="1">
<li></li>
</ol></li>
<li>record_loop</li>
</ol>
<p>整理一下： Use so100 joint to ee # calibrate In
<code>record.py</code> , keep calibration followed
lerobot-so100-calibrate <a
target="_blank" rel="noopener" href="https://huggingface.co/docs/lerobot/so100#calibrate">huggingface</a>
or <a
target="_blank" rel="noopener" href="https://github.com/huggingface/lerobot/blob/main/docs/source/so100.mdx">github</a>,
then get 2 json file indicating follower_id.json and leadr_id.json whose
id name should be written into
<code>SO100Follower/LeaderConfig(id=)</code></p>
<h1 id="record">record</h1>
<h2 id="code-pipeline">code pipeline</h2>
<p>modifiying settings in <code>record.py</code> in
<code>examples/so100_to_so100_EE</code> to set cameras/robots/datasets'
episodes. etc.</p>
<p>Download <a
href="It%20is%20highly%20recommended%20to%20use%20the%20urdf%20in%20the%20SO-ARM100%20repo:%20https://github.com/TheRobotStudio/SO-ARM100/blob/main/Simulation/SO101/so101_new_calib.urdf">ursf</a>
and tell code where to find it.</p>
<p>Then directly run python record.py to start record. In default the
dataset will be saved with state/action in ee type.</p>
<p>The code uses <code>follower_kinematics_solver</code> and
<code>leader_kinematics_solver</code> with ik solver
<strong>placo</strong>.</p>
<p>Three variables are calculated: - follower_joints_to_ee: change
follower joint_action to <code>action_ee</code>(dataset) -
leader_joints_to_ee: change leader to <code>state_ee</code>(dataset) -
ee_to_follower_joints: change <code>action_ee</code> to
<code>joint_action</code> to control follwer using inverse
kinematics.</p>
<p>Creating dataset using different <code>state</code> and
<code>action</code> setting(old one use joint now use end-effector
position)</p>
<p>Then loop_record using teleoperation..</p>
<h2 id="question-about-code">question about code</h2>
<ol type="1">
<li>Since the code control follower using <code>action_ee</code> then
calculate action_joint. Is this method useful to teleoperate different
type of robots with so100 leader? Since it uses ee to control, how the
joint going is decided by ik solver.</li>
<li>Is it right to use so101_urdf? I know there is little difference
between so100 and so101</li>
</ol>
<p>现在已经可以确定，ee的方式是有用的，接下来需要做 1.
可以保存action_joint吗？保存下来之后用长序列动作+一个环境相机效果采集作为视频交差
1. 写new_record.py能结合lerobot-record和ee/record.py的功能 2.
能可视化action，ee和joint都要 2.
保存action_joint之后，train的时候能读取，根据需要读取ee和joint的action/state
3. 模型推理出来的ee能转化到joint</p>
<h2 id="保存joint形式的数据">保存joint形式的数据</h2>
<p>record里面的调用形式 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the dataset</span></span><br><span class="line">dataset = LeRobotDataset.create(</span><br><span class="line">    repo_id=HF_REPO_ID,</span><br><span class="line">    fps=FPS,</span><br><span class="line">    features=combine_feature_dicts(</span><br><span class="line">        <span class="comment"># Run the feature contract of the pipelines</span></span><br><span class="line">        <span class="comment"># This tells you how the features would look like after the pipeline steps</span></span><br><span class="line">        aggregate_pipeline_dataset_features(</span><br><span class="line">            pipeline=leader_joints_to_ee,</span><br><span class="line">            initial_features=create_initial_features(action=leader.action_features),</span><br><span class="line">            use_videos=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">        aggregate_pipeline_dataset_features(</span><br><span class="line">            pipeline=follower_joints_to_ee,</span><br><span class="line">            initial_features=create_initial_features(observation=follower.observation_features),</span><br><span class="line">            use_videos=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    robot_type=follower.name,</span><br><span class="line">    use_videos=<span class="literal">True</span>,</span><br><span class="line">    image_writer_threads=<span class="number">4</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p><code>feature</code>关键字里面，流程是 <figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(raw robot data)</span><br><span class="line">    ↓</span><br><span class="line"><span class="built_in">create_initial_features</span>()</span><br><span class="line">    ↓</span><br><span class="line"><span class="built_in">aggregate_pipeline_dataset_features</span>(pipeline=leader_joints_to_ee)</span><br><span class="line">    ↓</span><br><span class="line"><span class="built_in">combine_feature_dicts</span>(...)   ← merge leader + follower 的特征</span><br><span class="line">    ↓</span><br><span class="line">LeRobotDataset<span class="selector-class">.create</span>(...)   ← 把特征schema + 数据保存为HF Dataset</span><br></pre></td></tr></table></figure></p>
<p><code>create_initial_features()</code>构建初始的特征结构（feature
dict），告诉 pipeline 原始输入有哪些字段。</p>
<p><code>aggregate_pipeline_dataset_features</code>这个函数主要的功能是把一个数据处理管线（<code>DataProcessorPipeline</code>）输出的特征，整理、筛选并格式化成可用于
Hugging Face LeRobot 数据集的标准特征字典。</p>
<p><code>combine_feature_dicts(*dicts)</code>把多个 pipeline 的特征
schema 合并</p>
<p>要求同时保存ee和joint形式的action/state，需要修改feature，在原来的pipeline基础上加保存原始数据的，修改dataset的feature</p>
<p>从头开始，怎样使用record 1. 准备代码 2.
下载模型文件不能只下载一个so101_new_calib.urdf 3. python
examples/...倒是可以直接运行成功</p>
<h3 id="record数据获取处理与保存">record数据获取、处理与保存</h3>
<p>2个函数，一个是dataset =
LeRobotDataset.create(features)，另一个是record_loop。分别负责dataset空数据集的feture设置和数据填入</p>
<ol type="1">
<li>features里面是把它原来的action和state变成了与joint
name符合的类型。参考lerobot_record的代码，发现了 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">teleop_action_processor, robot_action_processor, robot_observation_processor = make_default_processors()</span><br><span class="line"></span><br><span class="line">dataset_features = combine_feature_dicts(</span><br><span class="line">    aggregate_pipeline_dataset_features(</span><br><span class="line">        pipeline=teleop_action_processor,</span><br><span class="line">        initial_features=create_initial_features(</span><br><span class="line">            action=robot.action_features</span><br><span class="line">        ),  <span class="comment"># TODO(steven, pepijn): in future this should be come from teleop or policy</span></span><br><span class="line">        use_videos=cfg.dataset.video,</span><br><span class="line">    ),</span><br><span class="line">    aggregate_pipeline_dataset_features(</span><br><span class="line">        pipeline=robot_observation_processor,</span><br><span class="line">        initial_features=create_initial_features(observation=robot.observation_features),</span><br><span class="line">        use_videos=cfg.dataset.video,</span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li>如果直接新增，会导致action有多个部分，怎样区分开？</li>
<li>数据填入</li>
</ol>
<p>做法</p>
<ol type="1">
<li>定义新的feature</li>
</ol>
<p>整个流程： 1. lerobot-record
--config_path=tools/collect/collect_complex_movement.yaml
采集joint形式的data 2. python examples/so100_to_so100_EE/new_change.py
正运动学 3. python examples/so100_to_so100_EE/new_replay.py
用ee数据反解并执行，感觉还是有细微差距的 4. python
examples/so100_to_so100_EE/compare_2_actions.py 比较 1.
新问题：new_replay和compare_2_actions在计算action使用的obs不一样，要改成执行动作之后
2.
新问题2：transfer的时候没有问题吗？使用本地的state_joint数值，但是fk为什么要用state？</p>
<p>fk的计算过程in lerobot 🧩 一、record_loop 的总体数据流逻辑</p>
<p>在 record_loop() 中，执行循环 roughly 如下：</p>
<p>obs = robot.get_observation() # ① 获取机器人的关节状态（joints）
obs_processed = robot_observation_processor(obs) # ② 对 observation
做处理（通常FK）</p>
<p>act = teleop.get_action() # ③ 从 teleop 设备拿动作（leader 的
joints） act_processed_teleop = teleop_action_processor((act, obs)) # ④
对动作处理（通常FK）</p>
<p>robot_action_to_send = robot_action_processor((act_processed_teleop,
obs)) # ⑤ 做IK robot.send_action(robot_action_to_send) # ⑥
发给follower执行</p>
<p>从数据流角度看：</p>
<pre><code>teleop_action_processor：leader joints → leader EE

robot_action_processor：EE → follower joints

robot_observation_processor：follower joints → follower EE</code></pre>
<h1 id="metaworld">metaworld</h1>
<ol type="1">
<li><p>下载数据集（） export HF_ENDPOINT=https://hf-mirror.com hf
download lerobot/metaworld_mt50 --repo-type=dataset --token
复制token（需要能进huggingface官网）<br />
</p></li>
<li><p>环境 pip install -e ".[metaworld,smolvla]" hf download
HuggingFaceTB/SmolVLM2-500M-Instruct hf download
lerobot/smolvla_base</p></li>
<li><p>测试一个已经训练好的模型：检查metaworld环境 下载模型hf download
jadechoghari/smolvla_metaworld --token
复制token（需要能进huggingface官网） HF_HUB_OFFLINE=1 lerobot-eval<br />
--policy.path="jadechoghari/smolvla_metaworld"<br />
--env.type=metaworld<br />
--env.task=medium<br />
--eval.batch_size=1<br />
--eval.n_episodes=2</p></li>
<li><p>重新校准</p></li>
</ol>
<p>lerobot-calibrate<br />
--teleop.type=so100_leader<br />
--teleop.port=/dev/ttyACM1<br />
--teleop.id=middle_leader</p>
<p>lerobot-calibrate<br />
--robot.type=so100_follower<br />
--robot.port=/dev/ttyACM0<br />
--robot.id=middle_follower</p>
<ol start="2" type="1">
<li>保存的action不应该是follower读出来的，那只要保证不会跳变+精度足够就ok了？</li>
<li>之前没有安装深度相关的：pyrealsense2</li>
<li>采集：lerobot-record
--config_path=tools/collect/collect_joint_test.yaml</li>
<li>replay下joint控制的效果：lerobot-replay --robot.type=so100_follower
--robot.port=/dev/ttyACM0 --robot.id=follower
--dataset.repo_id=test_10/ee --dataset.episode=2
同时可以运行一个录制代码</li>
<li>joint变成ee：python examples/so100_to_so100_EE/new_change.py</li>
<li>visu</li>
</ol>
<p>感觉先collect再change不好，还是直接collect吧。
先在服务器上处理好模型等 1. 下载位置在~/.cache/huggingface/hub 2. export
HF_ENDPOINT=https://hf-mirror.com 3. hf download
HuggingFaceTB/SmolVLM2-500M-Instruct 4. hf download
lerobot/smolvla_base</p>
<p>选择哪种方式？ 看action保存的形式：使用pipeline的时候，
follower-&gt;raw_obs-&gt;robot_action_processor-&gt;obs_processed-&gt;dataset
leader-&gt;raw_act-&gt;teleop_action_process-&gt;act_processed_teleop=action_values-&gt;dataset
act_processed_teleop-&gt;robot_observation_processor-&gt;robot_action_sent-&gt;执行</p>
<p>所以还是保存record比较好，处理一下代码，修改了record_loop里面</p>
<p>rsync -avz /path/to/local/folder/
username@remote_host:/path/to/remote/folder/</p>
<p>rsync -avz test1110/
zhonglinyue@10.10.16.18:/home/zhonglinyue/.cache/huggingface/lerobot/test1110/</p>
<p>accelerate launch<br />
--multi_gpu<br />
--num_processes=2<br />
$(which lerobot-train)<br />
--policy.path=lerobot/smolvla_base<br />
--dataset.repo_id=test1110/merged<br />
--batch_size=64<br />
--steps=20000<br />
--output_dir=outputs/train/ee_action_ee_state<br />
--job_name=my_smolvla_training<br />
--policy.device=cuda<br />
--wandb.enable=false</p>
<p>CUDA_VISIBLE_DEVICES=0 HF_HUB_OFFLINE=1 lerobot-train<br />
--policy.path=lerobot/smolvla_base<br />
--dataset.repo_id=test1110/merged<br />
--batch_size=64<br />
--steps=20000<br />
--output_dir=outputs/train/ee_action_ee_state<br />
--job_name=my_smolvla_training<br />
--policy.device=cuda<br />
--wandb.enable=false<br />
--policy.push_to_hub=false<br />
--rename_map='{"observation.images.side": "observation.images.camera1",
"observation.images.wrist": "observation.images.camera2"}'</p>
<p>CUDA_VISIBLE_DEVICES=1 HF_HUB_OFFLINE=1 lerobot-train<br />
--policy.path=lerobot/smolvla_base<br />
--dataset.repo_id=test1110/merged<br />
--batch_size=64<br />
--steps=20000<br />
--output_dir=outputs/train/joint_action_joint_state<br />
--job_name=my_smolvla_training_joint<br />
--policy.device=cuda<br />
--wandb.enable=false<br />
--policy.push_to_hub=false<br />
--rename_map='{"observation.images.side": "observation.images.camera1",
"observation.images.wrist": "observation.images.camera2"}'</p>
<p>rsync -av --progress --exclude='*.safetensors'
zhonglinyue@10.10.16.18:/home/zhonglinyue/working_folder/lerobot/outputs/
/home/qwe/gene/lerobot/outputs/</p>
<p>python -m lerobot.async_inference.policy_server<br />
--host=10.10.16.18<br />
--port=8080</p>
<p>python -m lerobot.async_inference.robot_client<br />
--server_address=10.10.16.18:8080<br />
--robot.type=so100_follower<br />
--robot.port=/dev/ttyACM0<br />
--robot.id=follower<br />
--robot.cameras="{ camera1: {type: intelrealsense,
serial_number_or_name: 806312060427, width: 640, height: 480, fps: 30,
use_depth: False}, camera2: {type: opencv, index_or_path: 6, width: 640,
height: 480, fps: 30}}"<br />
--task="pick up the yellow sachet and place it into the box."<br />
--policy_type=smolvla<br />
--pretrained_name_or_path=outputs/train/ee_action_ee_state/checkpoints/020000/pretrained_model<br />
--policy_device=cuda<br />
--actions_per_chunk=50<br />
--chunk_size_threshold=0.5<br />
--aggregate_fn_name=weighted_average<br />
--debug_visualize_queue_size=True # record ## record_loop函数
<code>record_loop</code>里面，函数的输入参数有 -
teleop_action_processor：专门用于teleoperate，原始leader的act（joint）经过这个处理变成ee
- robot_action_processor：ee形式的action经过变成joint，可以交给机器执行
- robot_observation_processor：原始obs（joint）经过这个变成ee
分成四个部分： 1. 处理obs <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">obs = robot.get_observation()</span><br><span class="line">obs_processed = robot_observation_processor(obs)</span><br><span class="line"><span class="comment"># 此时obs_processed应该要处理所有observation作为前缀的feature了</span></span><br><span class="line">observation_frame = build_dataset_frame(dataset.features, obs_processed, prefix=OBS_STR)</span><br></pre></td></tr></table></figure> 2.
处理action，两种：policy/teleoperate <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">	action_values = predict_action(</span><br><span class="line">		observation=observation_frame,</span><br><span class="line">		policy=policy,)</span><br><span class="line">	<span class="comment"># 用模型推理出来的action调整格式</span></span><br><span class="line">	act_processed_policy: RobotAction = make_robot_action(action_values, dataset.features)</span><br><span class="line"><span class="keyword">elif</span> policy <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">isinstance</span>(teleop, Teleoperator):</span><br><span class="line">	<span class="comment"># 原始act</span></span><br><span class="line">	act = teleop.get_action()</span><br><span class="line">	act_processed_teleop = teleop_action_processor((act, obs))</span><br></pre></td></tr></table></figure> 3.
计算出要执行的action，也是两种policy和teleoperate <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Applies a pipeline to the action, default is IdentityProcessor</span></span><br><span class="line"><span class="keyword">if</span> policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> act_processed_policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">	action_values = act_processed_policy</span><br><span class="line">	robot_action_to_send = robot_action_processor((act_processed_policy, obs))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	action_values = act_processed_teleop</span><br><span class="line">	robot_action_to_send = robot_action_processor((act_processed_teleop, obs))</span><br><span class="line"><span class="comment"># 执行</span></span><br><span class="line">_sent_action = robot.send_action(robot_action_to_send)</span><br></pre></td></tr></table></figure> 4.
加入数据集 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">action_frame = build_dataset_frame(dataset.features, action_values, prefix=ACTION)</span><br><span class="line">frame = &#123;**observation_frame, **action_frame, <span class="string">&quot;task&quot;</span>: single_task&#125;</span><br><span class="line">dataset.add_frame(frame)</span><br></pre></td></tr></table></figure></p>
<h1 id="lerobot-ee">lerobot-ee</h1>
<h2 id="record-1">record</h2>
<h2 id="evaluate">evaluate</h2>
<p> the most core work in <code>predict_action</code> function. Where 1.
normalize and to CHW observation 2. preprocessor observation 3. policy
4. post processor policy output ### evaluate.py 1. robot <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">robot = SO100Follower(robot_config)</span><br></pre></td></tr></table></figure>
2. policy <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">policy = SmolVLAPolicy.from_pretrained(HF_MODEL_ID)</span><br></pre></td></tr></table></figure> 3. kinematics solver &amp;
ee-&gt;joints/joints-&gt;ee processor pipeline <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">kinematics_solver = RobotKinematics(</span><br><span class="line">    urdf_path=<span class="string">&quot;SO-ARM100/Simulation/SO101/so101_new_calib.urdf&quot;</span>,</span><br><span class="line">    target_frame_name=<span class="string">&quot;gripper_frame_link&quot;</span>,</span><br><span class="line">    joint_names=<span class="built_in">list</span>(robot.bus.motors.keys()),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build pipeline to convert EE action to joints action</span></span><br><span class="line">robot_ee_to_joints_processor = RobotProcessorPipeline[<span class="built_in">tuple</span>[RobotAction, RobotObservation], RobotAction](</span><br><span class="line">    [</span><br><span class="line">        EEBoundsAndSafety(</span><br><span class="line">            end_effector_bounds=&#123;<span class="string">&quot;min&quot;</span>: [-<span class="number">1.0</span>, -<span class="number">1.0</span>, -<span class="number">1.0</span>], <span class="string">&quot;max&quot;</span>: [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]&#125;,</span><br><span class="line">            max_ee_step_m=<span class="number">0.10</span>,</span><br><span class="line">        ),</span><br><span class="line">        InverseKinematicsEEToJoints(</span><br><span class="line">            kinematics=kinematics_solver,</span><br><span class="line">            motor_names=<span class="built_in">list</span>(robot.bus.motors.keys()),</span><br><span class="line">            initial_guess_current_joints=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">    ],</span><br><span class="line">    to_transition=robot_action_observation_to_transition,</span><br><span class="line">    to_output=transition_to_robot_action,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build pipeline to convert joints observation to EE observation</span></span><br><span class="line">robot_joints_to_ee_pose_processor = RobotProcessorPipeline[RobotObservation, RobotObservation](</span><br><span class="line">    steps=[</span><br><span class="line">        ForwardKinematicsJointsToEE(kinematics=kinematics_solver, motor_names=<span class="built_in">list</span>(robot.bus.motors.keys()))</span><br><span class="line">    ],</span><br><span class="line">    to_transition=observation_to_transition,</span><br><span class="line">    to_output=transition_to_observation,</span><br><span class="line">)</span><br></pre></td></tr></table></figure> 4. dataset
to save <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the dataset</span></span><br><span class="line">dataset = LeRobotDataset.create(</span><br><span class="line">    repo_id=HF_DATASET_ID,</span><br><span class="line">    fps=FPS,</span><br><span class="line">    features=combine_feature_dicts(</span><br><span class="line">        aggregate_pipeline_dataset_features(</span><br><span class="line">            pipeline=robot_joints_to_ee_pose_processor,</span><br><span class="line">            initial_features=create_initial_features(observation=robot.observation_features),</span><br><span class="line">            use_videos=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">        <span class="comment"># User for now should be explicit on the feature keys that were used for record</span></span><br><span class="line">        <span class="comment"># Alternatively, the user can pass the processor step that has the right features</span></span><br><span class="line">        aggregate_pipeline_dataset_features(</span><br><span class="line">            pipeline=make_default_teleop_action_processor(),</span><br><span class="line">            initial_features=create_initial_features(</span><br><span class="line">                action=&#123;</span><br><span class="line">                    <span class="string">f&quot;ee.<span class="subst">&#123;k&#125;</span>&quot;</span>: PolicyFeature(<span class="built_in">type</span>=FeatureType.ACTION, shape=(<span class="number">1</span>,))</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;z&quot;</span>, <span class="string">&quot;wx&quot;</span>, <span class="string">&quot;wy&quot;</span>, <span class="string">&quot;wz&quot;</span>, <span class="string">&quot;gripper_pos&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            ),</span><br><span class="line">            use_videos=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">    ),</span><br><span class="line">    robot_type=robot.name,</span><br><span class="line">    use_videos=<span class="literal">True</span>,</span><br><span class="line">    image_writer_threads=<span class="number">4</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure> 5. preprocessor, &amp; postprocessor, where
<code>dataset.meta.stats</code> is None since it creates a new dataset
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">preprocessor, postprocessor = make_pre_post_processors(</span><br><span class="line">    policy_cfg=policy,</span><br><span class="line">    pretrained_path=HF_MODEL_ID,</span><br><span class="line">    dataset_stats=dataset.meta.stats,</span><br><span class="line">    <span class="comment"># dataset_stats=None,</span></span><br><span class="line">    <span class="comment"># The inference device is automatically set to match the detected hardware, overriding any previous device settings from training to ensure compatibility.</span></span><br><span class="line">    preprocessor_overrides=&#123;<span class="string">&quot;device_processor&quot;</span>: &#123;<span class="string">&quot;device&quot;</span>: <span class="built_in">str</span>(policy.config.device)&#125;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure> 6. record_loop <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">record_loop(</span><br><span class="line">        robot=robot,</span><br><span class="line">        events=events,</span><br><span class="line">        fps=FPS,</span><br><span class="line">        policy=policy,</span><br><span class="line">        preprocessor=preprocessor,  <span class="comment"># Pass the pre and post policy processors</span></span><br><span class="line">        postprocessor=postprocessor,</span><br><span class="line">        dataset=dataset,</span><br><span class="line">        control_time_s=EPISODE_TIME_SEC,</span><br><span class="line">        single_task=TASK_DESCRIPTION,</span><br><span class="line">        display_data=<span class="literal">True</span>,</span><br><span class="line">        teleop_action_processor=make_default_teleop_action_processor(), <span class="comment"># 相当于不用管</span></span><br><span class="line">        robot_action_processor=robot_ee_to_joints_processor,</span><br><span class="line">        robot_observation_processor=robot_joints_to_ee_pose_processor,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure> ### record_loop 1.
initialize before every episode <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> preprocessor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> postprocessor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">	policy.reset()</span><br><span class="line">	preprocessor.reset()</span><br><span class="line">	postprocessor.reset()</span><br></pre></td></tr></table></figure> 2. get_observation(from
this is a total loop) <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obs = robot.get_observation()       </span><br></pre></td></tr></table></figure> 3. build lerobot type
observation_frame: A "frame" is a dictionary containing all the data for
a single timestep, formatted as numpy arrays according to the feature
specification. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">or</span> dataset <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">	observation_frame = build_dataset_frame(dataset.features, obs_processed, prefix=OBS_STR)</span><br></pre></td></tr></table></figure> 4. get action from policy <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> preprocessor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> postprocessor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">  action_values = predict_action(</span><br><span class="line">	  observation=observation_frame,</span><br><span class="line">	  policy=policy,</span><br><span class="line">	  device=get_safe_torch_device(policy.config.device),</span><br><span class="line">	  preprocessor=preprocessor,</span><br><span class="line">	  postprocessor=postprocessor,</span><br><span class="line">	  use_amp=policy.config.use_amp,</span><br><span class="line">	  task=single_task,</span><br><span class="line">	  robot_type=robot.robot_type,</span><br><span class="line">  )</span><br><span class="line">  act_processed_policy: RobotAction = make_robot_action(action_values, dataset.features)</span><br></pre></td></tr></table></figure>
5. calculate joint-space action <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> act_processed_policy <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">action_values = act_processed_policy</span><br><span class="line">robot_action_to_send = robot_action_processor((act_processed_policy, obs))</span><br></pre></td></tr></table></figure> 6. send action to robot
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># didn&#x27;t do action clip</span></span><br><span class="line">_sent_action = robot.send_action(robot_action_to_send)</span><br></pre></td></tr></table></figure></p>
<h3 id="predict_action">predict_action</h3>
<p>real observation-&gt;policy-&gt;action. Here <code>observation</code>
is Lerobotdataset type already. In
<code>src/lerobot/utils/control_utils.py</code> As described,it does: 1.
Prepares the observation by converting it to PyTorch tensors and adding
a batch dimension. 2. Runs the preprocessor pipeline on the observation.
3. Feeds the processed observation to the policy to get a raw action. 4.
Runs the postprocessor pipeline on the raw action. 5. Formats the final
action by removing the batch dimension and moving it to the CPU. Finaly
returns: A <code>torch.Tensor</code> containing the predicted action,
ready for the robot.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_action</span>(<span class="params"></span></span><br><span class="line"><span class="params">    observation: <span class="built_in">dict</span>[<span class="built_in">str</span>, np.ndarray],</span></span><br><span class="line"><span class="params">    policy: PreTrainedPolicy,</span></span><br><span class="line"><span class="params">    preprocessor: PolicyProcessorPipeline[<span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]],</span></span><br><span class="line"><span class="params">    postprocessor: PolicyProcessorPipeline[PolicyAction, PolicyAction],</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    observation = copy(observation)</span><br><span class="line">    <span class="keyword">with</span> (</span><br><span class="line">        torch.inference_mode(),</span><br><span class="line">        torch.autocast(device_type=device.<span class="built_in">type</span>) <span class="keyword">if</span> device.<span class="built_in">type</span> == <span class="string">&quot;cuda&quot;</span> <span class="keyword">and</span> use_amp <span class="keyword">else</span> nullcontext(),</span><br><span class="line">    ):</span><br><span class="line">        <span class="comment"># Convert to pytorch format: channel first and float32 in [0,1] with batch dimension</span></span><br><span class="line">        observation = prepare_observation_for_inference(observation, device, task, robot_type)</span><br><span class="line">        observation = preprocessor(observation)</span><br><span class="line">        action = policy.select_action(observation)</span><br><span class="line">        action = postprocessor(action)</span><br><span class="line">    <span class="keyword">return</span> action</span><br></pre></td></tr></table></figure>
<p>prepare_observation_for_inference takes a dictionary of NumPy arrays,
performs necessary preprocessing, and prepares it for model inference.
The steps include: 1. Converting NumPy arrays to PyTorch tensors. 2.
Normalizing and permuting image data (if any). 3. Adding a batch
dimension to each tensor. 4. Moving all tensors to the specified compute
device. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_observation_for_inference</span>(<span class="params"></span></span><br><span class="line"><span class="params">    observation: <span class="built_in">dict</span>[<span class="built_in">str</span>, np.ndarray],</span></span><br><span class="line"><span class="params">    device: torch.device,</span></span><br><span class="line"><span class="params"></span>) -&gt; RobotObservation:</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> observation:</span><br><span class="line">        observation[name] = torch.from_numpy(observation[name])</span><br><span class="line">        <span class="comment"># image process: /255 and to CHW</span></span><br><span class="line">         <span class="keyword">if</span> <span class="string">&quot;image&quot;</span> <span class="keyword">in</span> name:</span><br><span class="line">            observation[name] = observation[name].<span class="built_in">type</span>(torch.float32) / <span class="number">255</span></span><br><span class="line">            observation[name] = observation[name].permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).contiguous()</span><br><span class="line">        observation[name] = observation[name].unsqueeze(<span class="number">0</span>)</span><br><span class="line">        observation[name] = observation[name].to(device)</span><br><span class="line">    <span class="keyword">return</span> observation</span><br></pre></td></tr></table></figure></p>
<h3 id="local">local</h3>
<h3 id="async-1">async</h3>
<ul class="task-list">
<li><label><input
type="checkbox" />async以前的结构：改变输入和输出的action在哪里</label></li>
<li><label><input type="checkbox" />本地</label></li>
<li><label><input type="checkbox" />服务器 #### ee推理代码 主函数调用：
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment"># Main record loop</span></span><br><span class="line">    record_loop(</span><br><span class="line">        teleop_action_processor=make_default_teleop_action_processor(),</span><br><span class="line">        robot_action_processor=robot_ee_to_joints_processor,</span><br><span class="line">        robot_observation_processor=robot_joints_to_ee_pose_processor,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
[[#record_loop函数]]里面，action利用<code>robot_action_to_send = robot_action_processor((act_processed_policy, obs))</code>处理。ee推理里面定义为<code>robot_ee_to_joints_processor</code></label></li>
<li><label><input
type="checkbox" />所以改代码就要给async的action另外处理，判断条件就用name里面是否包含ee</label></li>
</ul>
<h4 id="修改async">修改async</h4>
<p>根据[[#async]]，直接修改本地接收到action之后的执行，在那之前加上action
pipeline+处理传给policy之前的state。
在robot_client_ee.py（和robot_client.py一样，改class名） 1.
init函数里增加ee和joint转换的工具 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment"># solver</span></span><br><span class="line">kinematics_solver = RobotKinematics(</span><br><span class="line">    urdf_path=<span class="string">&quot;SO-ARM100/Simulation/SO101/so101_new_calib.urdf&quot;</span>,</span><br><span class="line">    target_frame_name=<span class="string">&quot;gripper_frame_link&quot;</span>,</span><br><span class="line">    joint_names=<span class="built_in">list</span>(robot.bus.motors.keys()),</span><br><span class="line">)</span><br><span class="line">    <span class="comment"># ee到joint</span></span><br><span class="line">robot_ee_to_joints_processor = RobotProcessorPipeline[<span class="built_in">tuple</span>[RobotAction, RobotObservation], RobotAction](</span><br><span class="line">    steps=[</span><br><span class="line">        InverseKinematicsEEToJoints(</span><br><span class="line">            kinematics=kinematics_solver,</span><br><span class="line">            motor_names=<span class="built_in">list</span>(robot.bus.motors.keys()),</span><br><span class="line">            initial_guess_current_joints=<span class="literal">True</span>,</span><br><span class="line">        ),</span><br><span class="line">    ],</span><br><span class="line">    EEBoundsAndSafety(</span><br><span class="line">        end_effector_bounds=&#123;<span class="string">&quot;min&quot;</span>: [-<span class="number">1.0</span>, -<span class="number">1.0</span>, -<span class="number">1.0</span>], <span class="string">&quot;max&quot;</span>: [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]&#125;,</span><br><span class="line">        max_ee_step_m=<span class="number">0.10</span>,</span><br><span class="line">    ),</span><br><span class="line">    to_transition=robot_action_observation_to_transition,</span><br><span class="line">    to_output=transition_to_robot_action,</span><br><span class="line">)</span><br><span class="line">    <span class="comment"># joint到ee</span></span><br><span class="line">robot_joints_to_ee_pose_processor = RobotProcessorPipeline[RobotObservation, RobotObservation](</span><br><span class="line">    steps=[</span><br><span class="line">        ForwardKinematicsJointsToEE(kinematics=kinematics_solver, motor_names=<span class="built_in">list</span>(robot.bus.motors.keys()))</span><br><span class="line">    ],</span><br><span class="line">    to_transition=observation_to_transition,</span><br><span class="line">    to_output=transition_to_observation,</span><br><span class="line">)</span><br></pre></td></tr></table></figure> 2.
发给server的state从joint变成ee
control_loop_observation函数里给raw_obs处理成<code>ee_obs = self.joints_to_ee(raw_observation)</code>
3. server返回的action从ee变成joint，control_loop_action函数里把
<code>_performed_action = self.robot.send_action(self._action_tensor_to_action_dict(timed_action.get_action()))</code>替换成
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ee_action = self._action_tensor_to_action_dict(timed_action.get_action())</span><br><span class="line">joint_action = self.ee_to_follower_joints((ee_action, self.latest_joint_observation))</span><br><span class="line">_performed_action = self.robot.send_action(joint_action)</span><br></pre></td></tr></table></figure> 4.
<code>self.latest_joint_observation</code>应该是joint形式，保持不变，因为之前没有修改它
5. 修改feature 1.
这个feature要求和什么一致？RemotePolicyConfig里面传给服务器self.lerobot_features
= policy_specs.lerobot_features 2. 原来的形式：{'observation.state':
{'dtype': 'float32', 'shape': (6,), 'names': ['shoulder_pan.pos',
'shoulder_lift.pos', 'elbow_flex.pos', 'wrist_flex.pos',
'wrist_roll.pos', 'gripper.pos']}} 3. 应该要的形式：'observation.state':
{'dtype': 'float32', 'shape': (7,), 'names': ['ee.x', 'ee.y', 'ee.z',
'ee.wx', 'ee.wy', 'ee.wz', 'ee.gripper_pos']} 4. 最终的修改方案 1.
lerobot_features_ee_state['observation.state']=ee_feature['observation.state']
2.</p>
<h4 id="async执行">async执行</h4>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 666 /dev/ttyACM0</span><br><span class="line">python -m lerobot.async_inference.robot_client_ee \</span><br><span class="line">    --robot.type=so100_follower \</span><br><span class="line">    --robot.port=/dev/ttyACM0 \</span><br><span class="line">    --robot.id=follower \</span><br><span class="line">    --task=&quot;dummy&quot; \</span><br><span class="line">    --server_address=127.0.0.1:8080 \</span><br><span class="line">    --policy_type=act \</span><br><span class="line">    --pretrained_name_or_path=user/model \</span><br><span class="line">    --policy_device=mps \</span><br><span class="line">    --actions_per_chunk=50 \</span><br><span class="line">    --chunk_size_threshold=0.5 \</span><br><span class="line">    --aggregate_fn_name=weighted_average \</span><br><span class="line">    --debug_visualize_queue_size=False</span><br></pre></td></tr></table></figure>
<h4 id="执行">执行</h4>
<p>服务器端 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">HF_HUB_OFFLINE=1 CUDA_VISIBLE_DEVICES=0 python -m lerobot.async_inference.policy_server \</span><br><span class="line">     --host=10.10.16.18 \</span><br><span class="line">     --port=8080 \</span><br><span class="line">     --fps=30 \</span><br><span class="line">     --inference_latency=0.033 \</span><br><span class="line">     --obs_queue_timeout=1</span><br></pre></td></tr></table></figure></p>
<p>客户端，还是用yaml的形式不然太难看了。另外有一个之前没有注意的参数
robot里面的use_degrees，这个参数是用来告诉 当前新版硬件 API：
你传入和读出的关节位置是否使用“度数（degrees）”，还是使用新版统一的“归一化范围（–100…100）”。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test.yaml</span></span><br><span class="line"><span class="attr">server_address:</span> <span class="number">10.10</span><span class="number">.16</span><span class="number">.18</span><span class="string">:8080</span></span><br><span class="line"></span><br><span class="line"><span class="attr">robot:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">so100_follower</span></span><br><span class="line">  <span class="attr">port:</span> <span class="string">/dev/ttyACM0</span></span><br><span class="line">  <span class="attr">id:</span> <span class="string">follower</span></span><br><span class="line">  <span class="attr">cameras:</span></span><br><span class="line">    <span class="attr">camera1:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">intelrealsense</span></span><br><span class="line">      <span class="attr">serial_number_or_name:</span> <span class="number">806312060427</span></span><br><span class="line">      <span class="attr">width:</span> <span class="number">640</span></span><br><span class="line">      <span class="attr">height:</span> <span class="number">480</span></span><br><span class="line">      <span class="attr">fps:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">use_depth:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">camera2:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">opencv</span></span><br><span class="line">      <span class="attr">index_or_path:</span> <span class="number">6</span></span><br><span class="line">      <span class="attr">width:</span> <span class="number">640</span></span><br><span class="line">      <span class="attr">height:</span> <span class="number">480</span></span><br><span class="line">      <span class="attr">fps:</span> <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="attr">task:</span> <span class="string">pick</span> <span class="string">up</span> <span class="string">the</span> <span class="string">yellow</span> <span class="string">sachet</span> <span class="string">and</span> <span class="string">place</span> <span class="string">it</span> <span class="string">into</span> <span class="string">the</span> <span class="string">box.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">policy_type:</span> <span class="string">smolvla</span></span><br><span class="line"><span class="attr">pretrained_name_or_path:</span> <span class="string">outputs/train/ee_action_ee_state/checkpoints/020000/pretrained_model&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">actions_per_chunk:</span> <span class="number">50</span></span><br><span class="line"><span class="attr">chunk_size_threshold:</span> <span class="number">0.5</span></span><br><span class="line"><span class="attr">aggregate_fn_name:</span> <span class="string">weighted_average</span></span><br><span class="line"><span class="attr">debug_visualize_queue_size:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>执行 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HF_HUB_OFFLINE=1 python -m lerobot.async_inference.robot_client_ee --config_path=local_tools/eva/test.yaml</span><br></pre></td></tr></table></figure></p>
<p>有一个新问题，就是服务器端和本地真正执行predict的时候input不一样，因为async有给图片做和policy一致的resize
所以服务器里面最好加上dataset.meta.stats,</p>
<h1 id="debug配置文件自存">debug配置文件自存</h1>
<h2 id="服务器">服务器</h2>
<p>需要训练、async推理 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lerobot_train训练&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/zhonglinyue/miniconda3/envs/lerobot/bin/lerobot-train&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;--policy.path=lerobot/smolvla_base&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--dataset.repo_id=test1110/merged&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--batch_size=64&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--steps=20000&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--output_dir=outputs/train/joint_action_joint_state&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--job_name=my_smolvla_training_joint&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--policy.device=cuda&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--wandb.enable=false&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--policy.push_to_hub=false&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--rename_map=&#123;\&quot;observation.images.side\&quot;:\&quot;observation.images.camera1\&quot;,\&quot;observation.images.wrist\&quot;:\&quot;observation.images.camera2\&quot;&#125;&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="comment">// ,\&quot;joint_action\&quot;:\&quot;action\&quot;,\&quot;action\&quot;:\&quot;ee_action\&quot;,\&quot;action_is_pad\&quot;:\&quot;ee_action_is_pad\&quot;,\&quot;joint_action_is_pad\&quot;:\&quot;action_is_pad\&quot;</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;HF_HUB_OFFLINE&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;python&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/zhonglinyue/miniconda3/envs/lerobot/bin/python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/zhonglinyue/working_folder/lerobot&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;server async推理&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;module&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lerobot.async_inference.policy_server&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;--host=10.10.16.18&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--port=8080&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--fps=30&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--inference_latency=0.033&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--obs_queue_timeout=1&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;HF_HUB_OFFLINE&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;console&quot;</span><span class="punctuation">:</span> <span class="string">&quot;integratedTerminal&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;justMyCode&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;python&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/zhonglinyue/miniconda3/envs/lerobot/bin/python&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/zhonglinyue/working_folder/lerobot&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure> # 工具 rename feature.py
之前只写了修改action，发现state也要修改 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> lerobot.datasets.lerobot_dataset <span class="keyword">import</span> LeRobotDataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------- 加载旧数据集 ----------</span></span><br><span class="line">old_dataset = LeRobotDataset(</span><br><span class="line">    repo_id=<span class="string">&quot;test1110/merged&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------- 修改 features ----------</span></span><br><span class="line">new_features = old_dataset.features.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># action -&gt; ee_action</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;action&quot;</span> <span class="keyword">in</span> new_features:</span><br><span class="line">    old_action_feature = new_features.pop(<span class="string">&quot;action&quot;</span>)</span><br><span class="line">    new_features[<span class="string">&quot;ee_action&quot;</span>] = &#123;</span><br><span class="line">        <span class="string">&quot;dtype&quot;</span>: old_action_feature[<span class="string">&quot;dtype&quot;</span>],</span><br><span class="line">        <span class="string">&quot;shape&quot;</span>: old_action_feature[<span class="string">&quot;shape&quot;</span>],</span><br><span class="line">        <span class="string">&quot;names&quot;</span>: old_action_feature.get(<span class="string">&quot;names&quot;</span>, [<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(old_action_feature[<span class="string">&quot;shape&quot;</span>][<span class="number">0</span>])]),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># joint_action -&gt; action</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;joint_action&quot;</span> <span class="keyword">in</span> new_features:</span><br><span class="line">    joint_action_feature = new_features.pop(<span class="string">&quot;joint_action&quot;</span>)</span><br><span class="line">    new_features[<span class="string">&quot;action&quot;</span>] = &#123;</span><br><span class="line">        <span class="string">&quot;dtype&quot;</span>: joint_action_feature[<span class="string">&quot;dtype&quot;</span>],</span><br><span class="line">        <span class="string">&quot;shape&quot;</span>: joint_action_feature[<span class="string">&quot;shape&quot;</span>],</span><br><span class="line">        <span class="string">&quot;names&quot;</span>: joint_action_feature.get(<span class="string">&quot;names&quot;</span>, [<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(joint_action_feature[<span class="string">&quot;shape&quot;</span>][<span class="number">0</span>])]),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># observation.state -&gt; ee_state</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;observation.state&quot;</span> <span class="keyword">in</span> new_features:</span><br><span class="line">    state_feature = new_features.pop(<span class="string">&quot;observation.state&quot;</span>)</span><br><span class="line">    new_features[<span class="string">&quot;observation.ee_state&quot;</span>] = &#123;</span><br><span class="line">        <span class="string">&quot;dtype&quot;</span>: state_feature[<span class="string">&quot;dtype&quot;</span>],</span><br><span class="line">        <span class="string">&quot;shape&quot;</span>: state_feature[<span class="string">&quot;shape&quot;</span>],</span><br><span class="line">        <span class="string">&quot;names&quot;</span>: state_feature.get(<span class="string">&quot;names&quot;</span>, [<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(state_feature[<span class="string">&quot;shape&quot;</span>][<span class="number">0</span>])]),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># observation.joint_state -&gt; state</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;observation.joint_state&quot;</span> <span class="keyword">in</span> new_features:</span><br><span class="line">    joint_state_feature = new_features.pop(<span class="string">&quot;observation.joint_state&quot;</span>)</span><br><span class="line">    new_features[<span class="string">&quot;observation.state&quot;</span>] = &#123;</span><br><span class="line">        <span class="string">&quot;dtype&quot;</span>: joint_state_feature[<span class="string">&quot;dtype&quot;</span>],</span><br><span class="line">        <span class="string">&quot;shape&quot;</span>: joint_state_feature[<span class="string">&quot;shape&quot;</span>],</span><br><span class="line">        <span class="string">&quot;names&quot;</span>: joint_state_feature.get(<span class="string">&quot;names&quot;</span>, [<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(joint_state_feature[<span class="string">&quot;shape&quot;</span>][<span class="number">0</span>])]),</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(new_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------- 创建新的空数据集 ----------</span></span><br><span class="line">FPS = old_dataset.meta.fps</span><br><span class="line">ROBOT_TYPE = old_dataset.meta.robot_type</span><br><span class="line"></span><br><span class="line">new_dataset = LeRobotDataset.create(</span><br><span class="line">    repo_id=<span class="string">&quot;test1111/merged&quot;</span>,</span><br><span class="line">    features=new_features,</span><br><span class="line">    fps=FPS,</span><br><span class="line">    robot_type=ROBOT_TYPE,</span><br><span class="line">    use_videos=<span class="literal">True</span>,</span><br><span class="line">    image_writer_threads=<span class="number">4</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------- 遍历旧数据集，复制特征 ----------</span></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(old_dataset)):</span><br><span class="line">    sample = old_dataset[idx]</span><br><span class="line">    new_sample = sample.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除多余索引信息</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&quot;timestamp&quot;</span>, <span class="string">&quot;frame_index&quot;</span>, <span class="string">&quot;episode_index&quot;</span>, <span class="string">&quot;task_index&quot;</span>, <span class="string">&quot;index&quot;</span>]:</span><br><span class="line">        new_sample.pop(k, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># joint_action -&gt; action</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;joint_action&quot;</span> <span class="keyword">in</span> sample:</span><br><span class="line">        new_sample[<span class="string">&quot;action&quot;</span>] = sample[<span class="string">&quot;joint_action&quot;</span>].clone() <span class="keyword">if</span> <span class="built_in">isinstance</span>(sample[<span class="string">&quot;joint_action&quot;</span>], torch.Tensor) <span class="keyword">else</span> torch.tensor(sample[<span class="string">&quot;joint_action&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># action -&gt; ee_action</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;action&quot;</span> <span class="keyword">in</span> sample:</span><br><span class="line">        new_sample[<span class="string">&quot;ee_action&quot;</span>] = sample[<span class="string">&quot;action&quot;</span>].clone() <span class="keyword">if</span> <span class="built_in">isinstance</span>(sample[<span class="string">&quot;action&quot;</span>], torch.Tensor) <span class="keyword">else</span> torch.tensor(sample[<span class="string">&quot;action&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># observation.joint_state -&gt; state</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;observation.joint_state&quot;</span> <span class="keyword">in</span> sample:</span><br><span class="line">        new_sample[<span class="string">&quot;observation.state&quot;</span>] = sample[<span class="string">&quot;observation.joint_state&quot;</span>].clone() <span class="keyword">if</span> <span class="built_in">isinstance</span>(sample[<span class="string">&quot;observation.joint_state&quot;</span>], torch.Tensor) <span class="keyword">else</span> torch.tensor(sample[<span class="string">&quot;observation.joint_state&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># observation.state -&gt; ee_state</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;observation.state&quot;</span> <span class="keyword">in</span> sample:</span><br><span class="line">        new_sample[<span class="string">&quot;observation.ee_state&quot;</span>] = sample[<span class="string">&quot;observation.state&quot;</span>].clone() <span class="keyword">if</span> <span class="built_in">isinstance</span>(sample[<span class="string">&quot;observation.state&quot;</span>], torch.Tensor) <span class="keyword">else</span> torch.tensor(sample[<span class="string">&quot;observation.state&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除旧的 action 和 joint_action</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&quot;joint_action&quot;</span>]:</span><br><span class="line">        new_sample.pop(k, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除旧的 observation state</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&quot;observation.state&quot;</span>, <span class="string">&quot;observation.joint_state&quot;</span>]:</span><br><span class="line">        <span class="keyword">if</span> k <span class="keyword">in</span> new_sample:</span><br><span class="line">            new_sample.pop(k)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理图像 shape (C,H,W) -&gt; (H,W,C)</span></span><br><span class="line">    <span class="keyword">for</span> img_key <span class="keyword">in</span> [<span class="string">&quot;observation.images.wrist&quot;</span>, <span class="string">&quot;observation.images.side&quot;</span>]:</span><br><span class="line">        <span class="keyword">if</span> img_key <span class="keyword">in</span> new_sample:</span><br><span class="line">            new_sample[img_key] = new_sample[img_key].permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加到新数据集</span></span><br><span class="line">    new_dataset.add_frame(new_sample)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每1000帧保存一次</span></span><br><span class="line">    <span class="keyword">if</span> (idx + <span class="number">1</span>) % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        new_dataset.save_episode()</span><br><span class="line">        new_dataset.episode_buffer = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存剩余帧</span></span><br><span class="line"><span class="keyword">if</span> new_dataset.episode_buffer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> new_dataset.episode_buffer[<span class="string">&quot;size&quot;</span>] &gt; <span class="number">0</span>:</span><br><span class="line">    new_dataset.save_episode()</span><br><span class="line">    new_dataset.episode_buffer = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">new_dataset.finalize()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;新数据集已保存完成！&quot;</span>)</span><br></pre></td></tr></table></figure>
服务器发送给本地的应该是ee化之后的，没有其他改动</p>
<h1 id="async_inference">async_inference</h1>
<h2 id="inference-on-policy_srever">inference on policy_srever</h2>
<ol type="1">
<li>policy &amp; preprocessor/postprocessor <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">self.policy = policy_class.from_pretrained(policy_specs.pretrained_name_or_path)</span><br><span class="line"><span class="comment"># Load preprocessor and postprocessor, overriding device to match requested device</span></span><br><span class="line">device_override = &#123;<span class="string">&quot;device&quot;</span>: self.device&#125;</span><br><span class="line">self.preprocessor, self.postprocessor = make_pre_post_processors(</span><br><span class="line">	self.policy.config,</span><br><span class="line">	pretrained_path=policy_specs.pretrained_name_or_path,</span><br><span class="line">	preprocessor_overrides=&#123;</span><br><span class="line">		<span class="string">&quot;device_processor&quot;</span>: device_override,</span><br><span class="line">		<span class="string">&quot;rename_observations_processor&quot;</span>: &#123;<span class="string">&quot;rename_map&quot;</span>: policy_specs.rename_map&#125;,</span><br><span class="line">	&#125;,</span><br><span class="line">	postprocessor_overrides=&#123;<span class="string">&quot;device_processor&quot;</span>: device_override&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
<li>mostly in <code>_predict_action_chunk</code> triggered by
<code>action_chunk = self._predict_action_chunk(obs)</code>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_predict_action_chunk</span>(<span class="params">self, observation_t: TimedObservation</span>) -&gt; <span class="built_in">list</span>[TimedAction]:</span><br><span class="line">       <span class="string">&quot;&quot;&quot;Predict an action chunk based on an observation.</span></span><br><span class="line"><span class="string">       Pipeline:</span></span><br><span class="line"><span class="string">       1. Convert raw observation to LeRobot format</span></span><br><span class="line"><span class="string">       2. Apply preprocessor (tokenization, normalization, batching, device placement)</span></span><br><span class="line"><span class="string">       3. Run policy inference to get action chunk</span></span><br><span class="line"><span class="string">       4. Apply postprocessor (unnormalization, device movement)</span></span><br><span class="line"><span class="string">       5. Convert to TimedAction list</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;1. Prepare observation&quot;&quot;&quot;</span></span><br><span class="line">       observation: Observation = raw_observation_to_observation(</span><br><span class="line">           observation_t.get_observation(),</span><br><span class="line">           self.lerobot_features,</span><br><span class="line">           self.policy_image_features,</span><br><span class="line">       )</span><br><span class="line"></span><br><span class="line">       <span class="string">&quot;&quot;&quot;2. Apply preprocessor&quot;&quot;&quot;</span></span><br><span class="line">       observation = self.preprocessor(observation)</span><br><span class="line"></span><br><span class="line">       <span class="string">&quot;&quot;&quot;3. Get action chunk&quot;&quot;&quot;</span></span><br><span class="line">       action_tensor = self._get_action_chunk(observation)</span><br><span class="line">       <span class="string">&quot;&quot;&quot;4. Apply postprocessor&quot;&quot;&quot;</span></span><br><span class="line">       <span class="comment"># Apply postprocessor (handles unnormalization and device movement)</span></span><br><span class="line">       <span class="comment"># Postprocessor expects (B, action_dim) per action, but we have (B, chunk_size, action_dim)</span></span><br><span class="line">       <span class="comment"># So we process each action in the chunk individually</span></span><br><span class="line">       _, chunk_size, _ = action_tensor.shape</span><br><span class="line"></span><br><span class="line">       <span class="comment"># Process each action in the chunk</span></span><br><span class="line">       processed_actions = []</span><br><span class="line">       <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(chunk_size):</span><br><span class="line">           <span class="comment"># Extract action at timestep i: (B, action_dim)</span></span><br><span class="line">           single_action = action_tensor[:, i, :]</span><br><span class="line">           processed_action = self.postprocessor(single_action)</span><br><span class="line">           processed_actions.append(processed_action)</span><br><span class="line"></span><br><span class="line">       <span class="comment"># Stack back to (B, chunk_size, action_dim), then remove batch dim</span></span><br><span class="line">       action_tensor = torch.stack(processed_actions, dim=<span class="number">1</span>).squeeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">       <span class="string">&quot;&quot;&quot;5. Convert to TimedAction list&quot;&quot;&quot;</span></span><br><span class="line">       action_chunk = self._time_action_chunk(</span><br><span class="line">           observation_t.get_timestamp(), <span class="built_in">list</span>(action_tensor), observation_t.get_timestep()</span><br><span class="line">       )</span><br><span class="line">       <span class="keyword">return</span> action_chunk </span><br></pre></td></tr></table></figure></li>
<li>What does <code>raw_observation_to_observation</code> do?
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">raw_observation_to_observation</span>(<span class="params"></span></span><br><span class="line"><span class="params">    raw_observation: RawObservation,</span></span><br><span class="line"><span class="params">    lerobot_features: <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="built_in">dict</span>],</span></span><br><span class="line"><span class="params">    policy_image_features: <span class="built_in">dict</span>[<span class="built_in">str</span>, PolicyFeature],</span></span><br><span class="line"><span class="params"></span>) -&gt; Observation:</span><br><span class="line">    observation = &#123;&#125;</span><br><span class="line">    observation = prepare_raw_observation(raw_observation, lerobot_features, policy_image_features)</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> observation.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(v, torch.Tensor):  <span class="comment"># VLAs present natural-language instructions in observations</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;image&quot;</span> <span class="keyword">in</span> k:</span><br><span class="line">                <span class="comment"># Policy expects images in shape (B, C, H, W)</span></span><br><span class="line">                observation[k] = prepare_image(v).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            observation[k] = v</span><br><span class="line">    <span class="keyword">return</span> observation </span><br></pre></td></tr></table></figure></li>
<li>details in prepare_raw_observation and prepare_image
<ol type="1">
<li>prepare_raw_observation . In <code>resize</code> function I found
difference between local inference and async inference (the problem I
asked in title.) <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_raw_observation</span>(<span class="params"></span></span><br><span class="line"><span class="params">    robot_obs: RawObservation,</span></span><br><span class="line"><span class="params">    lerobot_features: <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="built_in">dict</span>],</span></span><br><span class="line"><span class="params">    policy_image_features: <span class="built_in">dict</span>[<span class="built_in">str</span>, PolicyFeature],</span></span><br><span class="line"><span class="params"></span>) -&gt; Observation:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Matches keys from the raw robot_obs dict to the keys expected by a given policy (passed as</span></span><br><span class="line"><span class="string">    policy_image_features).&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. &#123;motor.pos1:value1, motor.pos2:value2, ..., laptop:np.ndarray&#125; -&gt;</span></span><br><span class="line">    <span class="comment"># -&gt; &#123;observation.state:[value1,value2,...], observation.images.laptop:np.ndarray&#125;</span></span><br><span class="line">    <span class="comment"># Indeed it runs  build_dataset_frame(lerobot_features, robot_obs, prefix=OBS_STR)</span></span><br><span class="line">    lerobot_obs = make_lerobot_observation(robot_obs, lerobot_features)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. Greps all observation.images.&lt;&gt; keys</span></span><br><span class="line">    image_keys = <span class="built_in">list</span>(<span class="built_in">filter</span>(is_image_key, lerobot_obs))</span><br><span class="line">    <span class="comment"># state&#x27;s shape is expected as (B, state_dim)</span></span><br><span class="line">    state_dict = &#123;OBS_STATE: extract_state_from_raw_observation(lerobot_obs)&#125;</span><br><span class="line">    <span class="comment"># extract_images_from_raw_observation return torch.tensor(lerobot_obs[camera_key])</span></span><br><span class="line">    image_dict = &#123;</span><br><span class="line">        image_k: extract_images_from_raw_observation(lerobot_obs, image_k) <span class="keyword">for</span> image_k <span class="keyword">in</span> image_keys</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># Turns the image features to (C, H, W) with H, W matching the policy image features.</span></span><br><span class="line">    <span class="comment"># This reduces the resolution of the images</span></span><br><span class="line">    image_dict = &#123;</span><br><span class="line">        key: resize_robot_observation_image(torch.tensor(lerobot_obs[key]), policy_image_features[key].shape)</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> image_keys</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;task&quot;</span> <span class="keyword">in</span> robot_obs:</span><br><span class="line">        state_dict[<span class="string">&quot;task&quot;</span>] = robot_obs[<span class="string">&quot;task&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;**state_dict, **image_dict&#125;</span><br></pre></td></tr></table></figure></li>
<li>resize_robot_observation_image <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">resize_robot_observation_image</span>(<span class="params">image: torch.tensor, resize_dims: <span class="built_in">tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>]</span>) -&gt; torch.tensor:</span><br><span class="line">    <span class="keyword">assert</span> image.ndim == <span class="number">3</span>, <span class="string">f&quot;Image must be (C, H, W)! Received <span class="subst">&#123;image.shape&#125;</span>&quot;</span></span><br><span class="line">    <span class="comment"># (H, W, C) -&gt; (C, H, W) for resizing from robot obsevation resolution to policy image resolution</span></span><br><span class="line">    image = image.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    dims = (resize_dims[<span class="number">1</span>], resize_dims[<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># Add batch dimension for interpolate: (C, H, W) -&gt; (1, C, H, W)</span></span><br><span class="line">    image_batched = image.unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># Interpolate and remove batch dimension: (1, C, H, W) -&gt; (C, H, W)</span></span><br><span class="line">    resized = torch.nn.functional.interpolate(image_batched, size=dims, mode=<span class="string">&quot;bilinear&quot;</span>, align_corners=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> resized.squeeze(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li>
<li>prepare_image <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_image</span>(<span class="params">image: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Minimal preprocessing to turn int8 images to float32 in [0, 1], and create a memory-contiguous tensor&quot;&quot;&quot;</span></span><br><span class="line">    image = image.<span class="built_in">type</span>(torch.float32) / <span class="number">255</span></span><br><span class="line">    image = image.contiguous()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure></li>
</ol></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/robot/" rel="tag"># robot</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/10/22/%E8%91%B5%E8%8A%B1%E5%AE%9D%E5%85%B8%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AB%E8%91%B5%E8%8A%B1%E5%AE%9D%E5%85%B8/" rel="prev" title="研究修炼指南">
                  <i class="fa fa-angle-left"></i> 研究修炼指南
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/10/27/%E6%8E%A7%E5%88%B6/" rel="next" title="控制">
                  控制 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">milong26</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
